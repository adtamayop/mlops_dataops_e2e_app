{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline interactivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import urllib\n",
    "import tensorflow as tf\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.utils.dsl_utils import external_input\n",
    "from tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "DATA_RAW_JOIN_PATH = \"../data/raw/\"\n",
    "PIPELINE_PATH = \"./pipeline_test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componente de ingestión\n",
    "\n",
    "The ExampleGen TFX Pipeline component ingests data into TFX pipelines. It consumes external files/services to generate Examples which will be read by other TFX components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = InteractiveContext(\n",
    "  pipeline_name='mypipeline',\n",
    "  pipeline_root=PIPELINE_PATH\n",
    "  )\n",
    "\n",
    "input = example_gen_pb2.Input(\n",
    "    splits=[\n",
    "        example_gen_pb2.Input.Split(name=\"train\", pattern=\"train_data/*\"),\n",
    "        example_gen_pb2.Input.Split(name=\"validation\", pattern=\"val_data/*\"),\n",
    "        example_gen_pb2.Input.Split(name=\"test\", pattern=\"test_data/*\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_ingestion = CsvExampleGen(input_base=DATA_RAW_JOIN_PATH, input_config=input)\n",
    "context.run(data_ingestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de registros del dataset creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()\n",
    "artifact = data_ingestion.outputs['examples'].get()[0]\n",
    "print(artifact.split_names, artifact.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizar datos de mi example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the URI of the output artifact representing the training examples, which is a directory\n",
    "train_uri = os.path.join(data_ingestion.outputs['examples'].get()[0].uri, 'train')\n",
    "\n",
    "# Get the list of files in this directory (all compressed TFRecord files)\n",
    "tfrecord_filenames = [os.path.join(train_uri, name)\n",
    "                      for name in os.listdir(train_uri)]\n",
    "\n",
    "# Create a `TFRecordDataset` to read these files\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "\n",
    "# Iterate over the records and decode them.\n",
    "for tfrecord in dataset.take(1):\n",
    "  serialized_example = tfrecord.numpy()\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(serialized_example)\n",
    "  pp.pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componente de generación de estadísticas\n",
    "\n",
    "The StatisticsGen TFX pipeline component generates features statistics over both training and serving data, which can be used by other pipeline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_gen = StatisticsGen(    \n",
    "    examples=data_ingestion.outputs['examples'])    \n",
    "context.run(statistics_gen)\n",
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componente de generación del esquema de los datos\n",
    "\n",
    "Some TFX components use a description of your input data called a schema. The schema is an instance of schema.proto. It can specify data types for feature values, whether a feature has to be present in all examples, allowed value ranges, and other properties. A SchemaGen pipeline component will automatically generate a schema by inferring types, categories, and ranges from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_gen = SchemaGen(    \n",
    "    statistics=statistics_gen.outputs['statistics'],   \n",
    "    infer_feature_shape=True)    \n",
    "\n",
    "context.run(schema_gen)\n",
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componente de validación\n",
    "\n",
    "The ExampleValidator component uses Tensorflow Data Validation to validate the statistics of some splits on input examples against a schema.\n",
    "\n",
    "The ExampleValidator component identifies anomalies in training and serving data. The component can be configured to detect different classes of anomalies in the data. It can:\n",
    "\n",
    "perform validity checks by comparing data statistics against a schema that codifies expectations of the user.\n",
    "Schema Based Example Validation The ExampleValidator component identifies any anomalies in the example data by comparing data statistics computed by the StatisticsGen component against a schema. The schema codifies properties which the input data is expected to satisfy, and is provided and maintained by the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_gen.outputs['schema'])\n",
    "\n",
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_data_validation as tfdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that other_path points to another TFRecord file\n",
    "stats = tfdv.generate_statistics_from_tfrecord(data_location=\"/home/dot/Escritorio/trading_tfx/tfx_pipeline/pipeline_tfx/CsvExampleGen/examples/16/train/data_tfrecord-00000-of-00001.gz\")\n",
    "other_stats = tfdv.generate_statistics_from_tfrecord(data_location=\"/home/dot/Escritorio/trading_tfx/tfx_pipeline/pipeline_tfx/CsvExampleGen/examples/16/validation/data_tfrecord-00000-of-00001.gz\")\n",
    "\n",
    "schema = tfdv.infer_schema(stats)\n",
    "anomalies = tfdv.validate_statistics(statistics=other_stats, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.display_anomalies(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('trading_system': conda)",
   "name": "python376jvsc74a57bd04b4c04326adde5c76f03c34fb684de470eb694e199456809ded66c5d353454bf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
