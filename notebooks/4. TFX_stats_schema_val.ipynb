{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline interactivo de ingestión, generación de estadísticas, esquema, y validación de anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys  \n",
    "import pprint\n",
    "import tempfile\n",
    "import urllib\n",
    "import tfx\n",
    "import tensorflow as tf\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tfx.components import StatisticsGen\n",
    "import tensorflow_data_validation as tfdv\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componente de ingestión\n",
    "\n",
    "The ExampleGen TFX Pipeline component ingests data into TFX pipelines. It consumes external files/services to generate Examples which will be read by other TFX components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = InteractiveContext(  pipeline_name='notebook_pipeline_test',\n",
    "  pipeline_root=\"./output_notebook_pipeline\")\n",
    "\n",
    "DATA_RAW_JOIN_PATH = \"../data/processed/split/\"\n",
    "\n",
    "input = example_gen_pb2.Input(\n",
    "      splits=[\n",
    "          example_gen_pb2.Input.Split(name=\"train\", pattern=\"train/*\"),\n",
    "          example_gen_pb2.Input.Split(name=\"validation\", pattern=\"val/*\"),\n",
    "          example_gen_pb2.Input.Split(name=\"test\", pattern=\"test/*\"),\n",
    "      ]\n",
    "  )\n",
    "data_ingestion = tfx.components.CsvExampleGen(input_base=DATA_RAW_JOIN_PATH, input_config=input)\n",
    "context.run(data_ingestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de registros del dataset creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()\n",
    "artifact = data_ingestion.outputs['examples'].get()[0]\n",
    "print(artifact.split_names, artifact.uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizar datos de mi example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_uri = os.path.join(data_ingestion.outputs['examples'].get()[0].uri, 'split-train')\n",
    "\n",
    "tfrecord_filenames = [os.path.join(train_uri, name) for name in os.listdir(train_uri)]\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "\n",
    "for tfrecord in dataset.take(1):\n",
    "  serialized_example = tfrecord.numpy()\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(serialized_example)\n",
    "  pp.pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componente de generación de estadísticas\n",
    "\n",
    "The StatisticsGen TFX pipeline component generates features statistics over both training and serving data, which can be used by other pipeline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_gen = StatisticsGen(    \n",
    "    examples=data_ingestion.outputs['examples'])    \n",
    "context.run(statistics_gen)\n",
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componente de generación del esquema de los datos\n",
    "\n",
    "Some TFX components use a description of your input data called a schema. The schema is an instance of schema.proto. It can specify data types for feature values, whether a feature has to be present in all examples, allowed value ranges, and other properties. A SchemaGen pipeline component will automatically generate a schema by inferring types, categories, and ranges from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_gen = SchemaGen(    \n",
    "    statistics=statistics_gen.outputs['statistics'],   \n",
    "    infer_feature_shape=True)    \n",
    "\n",
    "context.run(schema_gen)\n",
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componente de validación\n",
    "\n",
    "The ExampleValidator component uses Tensorflow Data Validation to validate the statistics of some splits on input examples against a schema.\n",
    "\n",
    "The ExampleValidator component identifies anomalies in training and serving data. The component can be configured to detect different classes of anomalies in the data. It can:\n",
    "\n",
    "perform validity checks by comparing data statistics against a schema that codifies expectations of the user.\n",
    "Schema Based Example Validation The ExampleValidator component identifies any anomalies in the example data by comparing data statistics computed by the StatisticsGen component against a schema. The schema codifies properties which the input data is expected to satisfy, and is provided and maintained by the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_gen.outputs['schema'])\n",
    "\n",
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that other_path points to another TFRecord file\n",
    "stats = tfdv.generate_statistics_from_tfrecord(data_location=\"./output_notebook_pipeline/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\")\n",
    "other_stats = tfdv.generate_statistics_from_tfrecord(data_location=\"./output_notebook_pipeline/CsvExampleGen/examples/1/Split-validation/data_tfrecord-00000-of-00001.gz\")\n",
    "\n",
    "schema = tfdv.infer_schema(stats)\n",
    "anomalies = tfdv.validate_statistics(statistics=other_stats, schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.display_anomalies(anomalies)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
